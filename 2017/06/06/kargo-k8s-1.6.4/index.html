<!DOCTYPE html>
<html lang="zh-cmn-Hans" prefix="og: http://ogp.me/ns#" class="han-init">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <title>kargo kubernetes 1.6.4 &mdash; 山脚下的胖子.</title>
    <link rel="stylesheet" href="https://zmatsh.b0.upaiyun.com/assets/vendor/primer-css/css/primer.css">
    <link rel="stylesheet" href="https://zmatsh.b0.upaiyun.com/assets/vendor/primer-markdown/dist/user-content.min.css">
    <link rel="stylesheet" href="https://zmatsh.b0.upaiyun.com/assets/vendor/octicons/octicons/octicons.css">
    <link rel="stylesheet" href="https://zmatsh.b0.upaiyun.com/assets/css/components/collection.css">
    <link rel="stylesheet" href="https://zmatsh.b0.upaiyun.com/assets/css/components/repo-card.css">
    <link rel="stylesheet" href="https://zmatsh.b0.upaiyun.com/assets/css/sections/repo-list.css">
    <link rel="stylesheet" href="https://zmatsh.b0.upaiyun.com/assets/css/sections/mini-repo-list.css">
    <link rel="stylesheet" href="https://zmatsh.b0.upaiyun.com/assets/css/components/boxed-group.css">
    <link rel="stylesheet" href="https://zmatsh.b0.upaiyun.com/assets/css/globals/common.css">
    <link rel="stylesheet" href="https://zmatsh.b0.upaiyun.com/assets/vendor/share.js/dist/css/share.min.css">
    <link rel="stylesheet" href="https://zmatsh.b0.upaiyun.com/assets/css/globals/responsive.css">
    <link rel="stylesheet" href="https://zmatsh.b0.upaiyun.com/assets/css/posts/index.css">
    <!-- Latest compiled and minified CSS -->
    

    
    <link rel="canonical" href="http://firsh.me/2017/06/06/kargo-k8s-1.6.4/">
    <link rel="alternate" type="application/atom+xml" title="山脚下的胖子." href="/feed.xml">
    <link rel="shortcut icon" href="/favicon.ico">
    
    <meta property="og:title" content="kargo kubernetes 1.6.4">
      
    <meta name="keywords" content="docker">
    <meta name="og:keywords" content="docker">
      
    <meta name="description" content="1、初始化环境">
    <meta name="og:description" content="1、初始化环境">
      
    
    
        
    
    <meta property="og:url" content="http://firsh.me/2017/06/06/kargo-k8s-1.6.4/">
    <meta property="og:site_name" content="山脚下的胖子.">
    <meta property="og:type" content="article">
    <meta property="og:locale" content="zh_CN" />
    
    <meta property="article:published_time" content="2017-06-06">
    
    <script src="https://zmatsh.b0.upaiyun.com/assets/vendor/jquery/dist/jquery.min.js"></script>
    <script src="https://zmatsh.b0.upaiyun.com/assets/js/jquery-ui.js"></script>
    <script type="text/javascript">
    function toggleMenu() {
        var nav = document.getElementsByClassName("site-header-nav")[0];
        if (nav.style.display == "inline-flex") {
          nav.style.display = "none";
        } else {
          nav.style.display = "inline-flex";
        }
    }
    </script>
</head>
<body class="" data-mz="">
    <header class="site-header">
        <div class="container">
            <h1><a href="/" title="山脚下的胖子."><span class="octicon octicon-mark-github"></span> 山脚下的胖子.</a></h1>
            <button class="collapsed mobile-visible" type="button" onclick="toggleMenu();">
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <nav class="site-header-nav" role="navigation">
                
                <a href="/" class=" site-header-nav-item" target="" title="Index">Index</a>
                
                <a href="/categories/" class=" site-header-nav-item" target="" title="categories">categories</a>
                
                <a href="/open-source/" class=" site-header-nav-item" target="" title="open-source">open-source</a>
                
                <a href="/wiki/" class=" site-header-nav-item" target="" title="wiki">wiki</a>
                
                <a href="/links/" class=" site-header-nav-item" target="" title="links">links</a>
                
                <a href="/about/" class=" site-header-nav-item" target="" title="about">about</a>
                
            </nav>
        </div>
    </header>
    <!-- / header -->

    <section class="collection-head small geopattern" data-pattern-id="kargo kubernete">
<div class="container">
  <div class="columns">
    <div class="column three-fourths">
      <div class="collection-title">
        <h1 class="collection-header">kargo kubernetes 1.6.4</h1>
        <div class="collection-info">
          
          <span class="meta-info">
            <span class="octicon octicon-calendar"></span> 2017/06/06
          </span>
          
          
          <span class="meta-info">
            <span class="octicon octicon-file-directory"></span>
            <a href="/categories/#docker" title="docker">docker</a>
          </span>
          
        </div>
      </div>
    </div>
  </div>
</div>
</section>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
    (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-3969253077255521",
        enable_page_level_ads: true
    });
</script>
<!-- / .banner -->
<section class="container content">
<div class="columns">
  <div class="column three-fourths" >
    <article class="article-content markdown-body">
    <h1 id="1初始化环境">1、初始化环境</h1>

<blockquote>
  <p>kargo update k8s 1.6.4</p>
</blockquote>

<h2 id="11环境">1.1、环境：</h2>

<table>
  <thead>
    <tr>
      <th>节点</th>
      <th>IP</th>
      <th>角色</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>node-1</td>
      <td>10.6.0.52</td>
      <td>Master</td>
    </tr>
    <tr>
      <td>node-2</td>
      <td>10.6.0.53</td>
      <td>Master</td>
    </tr>
    <tr>
      <td>node-3</td>
      <td>10.6.0.55</td>
      <td>Node</td>
    </tr>
    <tr>
      <td>node-4</td>
      <td>10.6.0.56</td>
      <td>Node</td>
    </tr>
  </tbody>
</table>

<h2 id="12配置ssh-key-登陆">1.2、配置SSH Key 登陆</h2>

<div class="highlighter-rouge"><pre class="highlight"><code># 确保本机也可以 ssh 连接，否则下面部署失败

ssh-keygen -t rsa -N ""

ssh-copy-id -i /root/.ssh/id_rsa.pub 10.6.0.52

ssh-copy-id -i /root/.ssh/id_rsa.pub 10.6.0.53

ssh-copy-id -i /root/.ssh/id_rsa.pub 10.6.0.55

ssh-copy-id -i /root/.ssh/id_rsa.pub 10.6.0.56

</code></pre>
</div>

<h1 id="2获取-kargo">2、获取 Kargo</h1>

<blockquote>
  <p>Kargo 官方github
https://github.com/kubernetes-incubator/kargo</p>
</blockquote>

<h2 id="21安装基础软件">2.1、安装基础软件</h2>

<blockquote>
  <p>Kargo 是基于 ansible 统一部署，所以必须安装 ansible</p>
</blockquote>

<div class="highlighter-rouge"><pre class="highlight"><code># 安装 centos 额外的yum源
yum install -y epel-release

# 安装 软件
yum install -y python-pip python34 python-netaddr python34-pip ansible

# 如果 报 no test named 'equalto' ，需要升级 Jinja2
pip install --upgrade Jinja2
</code></pre>
</div>

<h2 id="22获取源码">2.2、获取源码</h2>

<div class="highlighter-rouge"><pre class="highlight"><code>git clone https://github.com/kubernetes-incubator/kargo
</code></pre>
</div>

<h2 id="23编辑配置文件">2.3、编辑配置文件</h2>

<div class="highlighter-rouge"><pre class="highlight"><code>cd kargo

vim inventory/group_vars/k8s-cluster.yml


这里主要修改一些 网段，密码 等信息


</code></pre>
</div>

<h2 id="24生成集群配置文件">2.4、生成集群配置文件</h2>

<div class="highlighter-rouge"><pre class="highlight"><code>cd kargo

CONFIG_FILE=inventory/inventory.cfg python3 contrib/inventory_builder/inventory.py 10.6.0.52 10.6.0.53 10.6.0.55 10.6.0.56

# 输入如下：

DEBUG: Adding group all
DEBUG: Adding group kube-master
DEBUG: Adding group kube-node
DEBUG: Adding group etcd
DEBUG: Adding group k8s-cluster:children
DEBUG: Adding group calico-rr
DEBUG: adding host node1 to group all
DEBUG: adding host node2 to group all
DEBUG: adding host node3 to group all
DEBUG: adding host node4 to group all
DEBUG: adding host kube-node to group k8s-cluster:children
DEBUG: adding host kube-master to group k8s-cluster:children
DEBUG: adding host node1 to group etcd
DEBUG: adding host node2 to group etcd
DEBUG: adding host node3 to group etcd
DEBUG: adding host node1 to group kube-master
DEBUG: adding host node2 to group kube-master
DEBUG: adding host node1 to group kube-node
DEBUG: adding host node2 to group kube-node
DEBUG: adding host node3 to group kube-node
DEBUG: adding host node4 to group kube-node


# 生成的配置文件在当前目录，既 kargo/inventory 目录下 inventory.cfg

# 配置文件如下(默认配置双master，可自行修改)：
# SSH 非 22 端口 添加 ansible_port=xxx

[all]
node1    ansible_host=10.6.0.52 ansible_port=33 ip=10.6.0.52
node2    ansible_host=10.6.0.53 ansible_port=33 ip=10.6.0.53
node3    ansible_host=10.6.0.55 ansible_port=33 ip=10.6.0.55
node4    ansible_host=10.6.0.56 ansible_port=33 ip=10.6.0.56

[kube-master]
node1    
node2    

[kube-node]
node1    
node2    
node3    
node4    

[etcd]
node1    
node2    
node3    

[k8s-cluster:children]
kube-node        
kube-master      

[calico-rr]

</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code># 1.6.4 镜像下载

http://pan.baidu.com/s/1nvUc5mx


</code></pre>
</div>

<h2 id="25部署集群">2.5、部署集群</h2>

<div class="highlighter-rouge"><pre class="highlight"><code># 执行如下命令，请确保SSH KEY 登陆, 端口一致

ansible-playbook -i inventory/inventory.cfg cluster.yml -b -v --private-key=~/.ssh/id_rsa

</code></pre>
</div>

<h2 id="26测试">2.6、测试</h2>

<div class="highlighter-rouge"><pre class="highlight"><code># 两个 master 中使用 kubectl get nodes

[root@k8s-node-1 ~]# kubectl get nodes
NAME         STATUS    AGE       VERSION
k8s-node-1   Ready     16m       v1.6.4+coreos.0
k8s-node-2   Ready     20m       v1.6.4+coreos.0
k8s-node-3   Ready     16m       v1.6.4+coreos.0
k8s-node-4   Ready     16m       v1.6.4+coreos.0



[root@k8s-node-2 ~]# kubectl get nodes
NAME         STATUS    AGE       VERSION
k8s-node-1   Ready     11m       v1.6.4+coreos.0
k8s-node-2   Ready     16m       v1.6.4+coreos.0
k8s-node-3   Ready     11m       v1.6.4+coreos.0
k8s-node-4   Ready     11m       v1.6.4+coreos.0




[root@k8s-node-1 ~]# kubectl get pods --namespace=kube-system
NAME                                  READY     STATUS    RESTARTS   AGE
dnsmasq-411420702-z0gkx               1/1       Running   0          16m
dnsmasq-autoscaler-1155841093-1hxdl   1/1       Running   0          16m
elasticsearch-logging-v1-kgt1t        1/1       Running   0          15m
elasticsearch-logging-v1-vm4bd        1/1       Running   0          15m
fluentd-es-v1.22-6gql6                1/1       Running   0          15m
fluentd-es-v1.22-8zkjh                1/1       Running   0          15m
fluentd-es-v1.22-cjskv                1/1       Running   0          15m
fluentd-es-v1.22-j4857                1/1       Running   0          15m
kibana-logging-2924323056-x3vjk       1/1       Running   0          15m
kube-apiserver-k8s-node-1             1/1       Running   0          15m
kube-apiserver-k8s-node-2             1/1       Running   0          20m
kube-controller-manager-k8s-node-1    1/1       Running   0          16m
kube-controller-manager-k8s-node-2    1/1       Running   0          21m
kube-proxy-k8s-node-1                 1/1       Running   0          16m
kube-proxy-k8s-node-2                 1/1       Running   0          21m
kube-proxy-k8s-node-3                 1/1       Running   0          16m
kube-proxy-k8s-node-4                 1/1       Running   0          16m
kube-scheduler-k8s-node-1             1/1       Running   0          16m
kube-scheduler-k8s-node-2             1/1       Running   0          21m
kubedns-3830354952-pfl7n              3/3       Running   4          16m
kubedns-autoscaler-54374881-64x6d     1/1       Running   0          16m
nginx-proxy-k8s-node-3                1/1       Running   0          16m
nginx-proxy-k8s-node-4                1/1       Running   0          16m



[root@k8s-node-1 ~]# kubectl get pods
NAME                             READY     STATUS    RESTARTS   AGE
netchecker-agent-3x3sj           1/1       Running   0          16m
netchecker-agent-ggxs2           1/1       Running   0          16m
netchecker-agent-hostnet-45k84   1/1       Running   0          16m
netchecker-agent-hostnet-kwvc8   1/1       Running   0          16m
netchecker-agent-hostnet-pwm77   1/1       Running   0          16m
netchecker-agent-hostnet-z4gmq   1/1       Running   0          16m
netchecker-agent-q3291           1/1       Running   0          16m
netchecker-agent-qtml6           1/1       Running   0          16m
netchecker-server                1/1       Running   0          16m


</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code># 配置一个 nginx deplyment 与 nginx  service

apiVersion: extensions/v1beta1 
kind: Deployment 
metadata: 
  name: nginx-dm
spec: 
  replicas: 2
  template: 
    metadata: 
      labels: 
        name: nginx 
    spec: 
      containers: 
        - name: nginx 
          image: nginx:alpine 
          imagePullPolicy: IfNotPresent
          ports: 
            - containerPort: 80

</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>apiVersion: v1 
kind: Service
metadata: 
  name: nginx-dm 
spec: 
  ports: 
    - port: 80
      targetPort: 80
      protocol: TCP 
  selector: 
    name: nginx
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code># 导入 yaml 文件


[root@k8s-node-1 ~]# kubectl apply -f nginx.yaml 
deployment "nginx-dm" created
service "nginx-dm" created



[root@k8s-node-1 ~]# kubectl get pods -o wide
NAME                             READY     STATUS    RESTARTS   AGE       IP              NODE
nginx-dm-4194680597-0h071        1/1       Running   0          9m        10.233.75.8     k8s-node-4
nginx-dm-4194680597-dzcf3        1/1       Running   0          9m        10.233.76.124   k8s-node-3


[root@k8s-node-1 ~]# kubectl get svc -o wide    
NAME                 CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE       SELECTOR
kubernetes           10.233.0.1      &lt;none&gt;        443/TCP          39m       &lt;none&gt;
netchecker-service   10.233.0.126    &lt;nodes&gt;       8081:31081/TCP   33m       app=netchecker-server
nginx-dm             10.233.56.138   &lt;none&gt;        80/TCP           10m       name=nginx

</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code># 部署一个  curl 的 pods 用来测试 内部通信


apiVersion: v1
kind: Pod
metadata:
  name: curl
spec:
  containers:
  - name: curl
    image: radial/busyboxplus:curl
    command:
    - sh
    - -c
    - while true; do sleep 1; done

</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code># 导入 yaml 文件

[root@k8s-node-1 ~]# kubectl apply -f curl.yaml 
pod "curl" created

    
[root@k8s-node-1 ~]# kubectl get pods -o wide
NAME                             READY     STATUS    RESTARTS   AGE       IP              NODE
curl                             1/1       Running   0          2m        10.233.75.22    k8s-node-4


</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code># 测试 curl --&gt; nginx-svc


[root@k8s-node-1 ~]# kubectl exec -it curl curl nginx-dm


<span class="cp">&lt;!DOCTYPE html&gt;</span>
<span class="nt">&lt;html&gt;</span>
<span class="nt">&lt;head&gt;</span>
<span class="nt">&lt;title&gt;</span>Welcome to nginx!<span class="nt">&lt;/title&gt;</span>
<span class="nt">&lt;style&gt;</span>
    <span class="nt">body</span> <span class="p">{</span>
        <span class="nl">width</span><span class="p">:</span> <span class="m">35em</span><span class="p">;</span>
        <span class="nl">margin</span><span class="p">:</span> <span class="m">0</span> <span class="nb">auto</span><span class="p">;</span>
        <span class="nl">font-family</span><span class="p">:</span> <span class="n">Tahoma</span><span class="p">,</span> <span class="n">Verdana</span><span class="p">,</span> <span class="n">Arial</span><span class="p">,</span> <span class="nb">sans-serif</span><span class="p">;</span>
    <span class="p">}</span>
<span class="nt">&lt;/style&gt;</span>
<span class="nt">&lt;/head&gt;</span>
<span class="nt">&lt;body&gt;</span>
<span class="nt">&lt;h1&gt;</span>Welcome to nginx!<span class="nt">&lt;/h1&gt;</span>
<span class="nt">&lt;p&gt;</span>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.<span class="nt">&lt;/p&gt;</span>

<span class="nt">&lt;p&gt;</span>For online documentation and support please refer to
<span class="nt">&lt;a</span> <span class="na">href=</span><span class="s">"http://nginx.org/"</span><span class="nt">&gt;</span>nginx.org<span class="nt">&lt;/a&gt;</span>.<span class="nt">&lt;br/&gt;</span>
Commercial support is available at
<span class="nt">&lt;a</span> <span class="na">href=</span><span class="s">"http://nginx.com/"</span><span class="nt">&gt;</span>nginx.com<span class="nt">&lt;/a&gt;</span>.<span class="nt">&lt;/p&gt;</span>

<span class="nt">&lt;p&gt;&lt;em&gt;</span>Thank you for using nginx.<span class="nt">&lt;/em&gt;&lt;/p&gt;</span>
<span class="nt">&lt;/body&gt;</span>
<span class="nt">&lt;/html&gt;</span>

</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code># 创建一个 zk  集群 zk-deplyment  和 service


apiVersion: extensions/v1beta1
kind: Deployment 
metadata: 
  name: zookeeper-1
spec: 
  replicas: 1
  template: 
    metadata: 
      labels: 
        name: zookeeper-1 
    spec: 
      containers: 
        - name: zookeeper-1
          image: jicki/zk:alpine 
          imagePullPolicy: IfNotPresent
          env:
          - name: NODE_ID
            value: "1"
          - name: NODES
            value: "0.0.0.0,zookeeper-2,zookeeper-3"
          ports:
          - containerPort: 2181

</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>apiVersion: extensions/v1beta1 
kind: Deployment
metadata:
  name: zookeeper-2
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: zookeeper-2
    spec:
      containers:
        - name: zookeeper-2
          image: jicki/zk:alpine
          imagePullPolicy: IfNotPresent
          env:
          - name: NODE_ID
            value: "2"
          - name: NODES
            value: "zookeeper-1,0.0.0.0,zookeeper-3"
          ports:
          - containerPort: 2181

</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: zookeeper-3
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: zookeeper-3
    spec:
      containers:
        - name: zookeeper-3
          image: jicki/zk:alpine
          imagePullPolicy: IfNotPresent
          env:
          - name: NODE_ID
            value: "3"
          - name: NODES
            value: "zookeeper-1,zookeeper-2,0.0.0.0"
          ports:
          - containerPort: 2181
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>apiVersion: v1 
kind: Service 
metadata: 
  name: zookeeper-1 
  labels:
    name: zookeeper-1
spec: 
  ports: 
    - name: client
      port: 2181
      protocol: TCP
    - name: followers
      port: 2888
      protocol: TCP
    - name: election
      port: 3888
      protocol: TCP
  selector: 
    name: zookeeper-1

</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>
apiVersion: v1 
kind: Service 
metadata: 
  name: zookeeper-2
  labels:
    name: zookeeper-2
spec: 
  ports: 
    - name: client
      port: 2181
      protocol: TCP
    - name: followers
      port: 2888
      protocol: TCP
    - name: election
      port: 3888
      protocol: TCP
  selector: 
    name: zookeeper-2

</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>
apiVersion: v1 
kind: Service 
metadata: 
  name: zookeeper-3
  labels:
    name: zookeeper-3
spec: 
  ports: 
    - name: client
      port: 2181
      protocol: TCP
    - name: followers
      port: 2888
      protocol: TCP
    - name: election
      port: 3888
      protocol: TCP
  selector: 
    name: zookeeper-3

</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code># 查看状态  pods 与 service

[root@k8s-node-1 ~]# kubectl get pods -o wide
NAME                             READY     STATUS    RESTARTS   AGE       IP              NODE
zookeeper-1-3762028479-gd5rm     1/1       Running   0          1m        10.233.76.125   k8s-node-3
zookeeper-2-4266983361-cz80w     1/1       Running   0          1m        10.233.75.23    k8s-node-4
zookeeper-3-479264707-hlv3x      1/1       Running   0          1m        10.233.75.24    k8s-node-4



[root@k8s-node-1 ~]# kubectl get svc -o wide    
NAME                 CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE       SELECTOR
zookeeper-1          10.233.25.46    &lt;none&gt;        2181/TCP,2888/TCP,3888/TCP   1m        name=zookeeper-1
zookeeper-2          10.233.49.4     &lt;none&gt;        2181/TCP,2888/TCP,3888/TCP   1m        name=zookeeper-2
zookeeper-3          10.233.50.206   &lt;none&gt;        2181/TCP,2888/TCP,3888/TCP   1m        name=zookeeper-3

</code></pre>
</div>

<h2 id="27部署一个-nginx-ingress">2.7、部署一个 Nginx Ingress</h2>

<blockquote>
  <p>Kubernetes 暴露服务的方式目前只有三种：LoadBlancer Service、NodePort Service、Ingress；
什么是 Ingress ?  Ingress 就是利用 nginx haproxy 等负载均衡工具来暴露 Kubernetes 服务。</p>
</blockquote>

<div class="highlighter-rouge"><pre class="highlight"><code>
# 首先 部署一个 http-backend, 用于统一转发 没有的域名 到指定页面。
# 官方 nginx  ingress 库 https://github.com/kubernetes/ingress/tree/master/examples/deployment/nginx

</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code># 下载官方的 nginx  backend 文件

curl -O https://raw.githubusercontent.com/kubernetes/ingress/master/examples/deployment/nginx/default-backend.yaml


# 直接导入既可
[root@k8s-node-1 ~]# kubectl apply -f default-backend.yaml 
deployment "default-http-backend" created
service "default-http-backend" created

# 查看 deployment 与 service

[root@k8s-node-1 ~]# kubectl get deployment --namespace=kube-system
NAME                   DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
default-http-backend   1         1         1            1           33m


[root@k8s-node-1 ~]# kubectl get svc --namespace=kube-system       
NAME                    CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE
default-http-backend    10.233.20.232   &lt;none&gt;        80/TCP          33m

</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code># 部署 Ingress Controller 组件

</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code># 下载 官方 nginx-ingress-controller 的yaml文件

curl -O https://raw.githubusercontent.com/kubernetes/ingress/master/examples/deployment/nginx/nginx-ingress-controller.yaml

# 编辑 yaml 文件，打开 hostNetwork: true , 将端口绑定到宿主机中
# 这里面deployment 默认只启动了一个pods, 这里可以修改 kind: Deployment 为 kind: DaemonSet  并注释掉 replicas
# 或者 修改 replicas: 1  为 N 


vi nginx-ingress-controller.yaml

将 hostNetwork: true  前面的注释去掉



# 导入 yaml 文件

[root@k8s-node-1 ~]# kubectl apply -f nginx-ingress-controller.yaml 
deployment "nginx-ingress-controller" created


# 查看 deployment  或者  daemonsets
[root@k8s-node-1 yaml]# kubectl get deployment --namespace=kube-system
NAME                       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx-ingress-controller   1         1         1            1           31s


[root@k8s-node-1 yaml]# kubectl get daemonsets --namespace=kube-system
NAME                       DESIRED   CURRENT   READY     NODE-SELECTOR   AGE
nginx-ingress-controller   4         4         4         &lt;none&gt;          1m


</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code># 最后开始 部署 Ingress
# 这里请先看看官方 ingress 的 yaml 写法
# https://kubernetes.io/docs/user-guide/ingress/


# 我们使用 之前创建的 nginx-dm  service，我们来写一个 ingress
# 首先查看一下 svc 

[root@k8s-node-1 yaml]# kubectl get svc
NAME                 CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE
kubernetes           10.233.0.1      &lt;none&gt;        443/TCP                      1d
netchecker-service   10.233.0.126    &lt;nodes&gt;       8081:31081/TCP               1d
nginx-dm             10.233.56.138   &lt;none&gt;        80/TCP                       1d
zookeeper-1          10.233.25.46    &lt;none&gt;        2181/TCP,2888/TCP,3888/TCP   1d
zookeeper-2          10.233.49.4     &lt;none&gt;        2181/TCP,2888/TCP,3888/TCP   1d
zookeeper-3          10.233.50.206   &lt;none&gt;        2181/TCP,2888/TCP,3888/TCP   1d



# 创建 yaml 文件， 这里特别注意，如果 svc 在 kube-system 下
# 必须在 metadata: 下面添加 namespace: kube-system 指定命名空间

vim nginx-ingress.yaml

apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: nginx-ingress
spec:
  rules:
  - host: nginx.jicki.me
    http:
      paths:
      - backend:
          serviceName: nginx-dm
          servicePort: 80


# 导入 yaml 文件

[root@k8s-node-1 ~]# kubectl apply -f nginx-ingress.yaml 
ingress "nginx-ingress" created


# 查看一下 创建的 ingress

[root@k8s-node-1 ~]# kubectl get ingresses
NAME            HOSTS            ADDRESS   PORTS     AGE
nginx-ingress   nginx.jicki.me             80        17s

# 这里显示 ADDRESS 为 空 实际上 所有 master 与 nodes 都绑定了
# 将域名解析到 任何一个 IP 上都可以。






# 下面访问 http://nginx.jicki.me/

# 这里注意，Ingresses 只做简单的端口转发。


</code></pre>
</div>

<p><img src="http://jicki.me/images/posts/kagro/1.png" alt="nginx" /></p>

<h1 id="维护-faq">维护 FAQ</h1>

<div class="highlighter-rouge"><pre class="highlight"><code># 卸载

cd kargo

ansible-playbook -i inventory/inventory.cfg reset.yml -b -v --private-key=~/.ssh/id_rsa

</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code># 增加节点

# 首先编辑 inventory/inventory.cfg  增加一个节点 例：node5

[kube-node]
node1
node2
node3
node4
node5


# 执行命令 使用 --limit 参数

ansible-playbook -i inventory/inventory.cfg cluster.yml -b -v --private-key=~/.ssh/id_rsa --limit node5


</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code># 报错1
# hostname 的问题
# 部署 kargo 必须配置 hostname 否则 多 master 会出现 无法创建 api 等 pods
# 如果 执行了 ansible-playbook 之前没改 hostname 必须删除 /tmp 下的 node[N]
# 否则更改 /etc/hosts 失败
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code># 报错 2

TASK [vault : check_vault | Set fact about the Vault cluster's initialization state] ***
Monday 10 April 2017  17:47:42 +0800 (0:00:00.088)       0:01:22.030 ********** 
fatal: [node1]: FAILED! =&gt; {"failed": true, "msg": "'dict object' has no attribute 'vault'"}
fatal: [node3]: FAILED! =&gt; {"failed": true, "msg": "'dict object' has no attribute 'vault'"}

# 解决方案 升级 ansible =&gt; 2.2.1.0

</code></pre>
</div>


    </article>
    <div class="share">
      <div class="share-component"></div>
    </div>
    <div class="comment">
      
  
      
        
        <!-- Disqus Protection, see https://github.com/mzlogin/mzlogin.github.io/issues/2 -->
        
        
          <div id="disqus_thread"></div>
          <script>
            var disqus_config = function () {
              this.page.url = 'http://firsh.me/2017/06/06/kargo-k8s-1.6.4/';
              this.page.identifier = '/2017/06/06/kargo-k8s-1.6.4/';
              this.page.title = 'kargo kubernetes 1.6.4';
            };
            (function() { // DON'T EDIT BELOW THIS LINE
              var d = document, s = d.createElement('script');

              s.type = 'text/javascript';
              s.async = true;
              var shortname = 'zmatsh';

              s.src = '//' + shortname + '.disqus.com/embed.js';

              s.setAttribute('data-timestamp', +new Date());
              (d.head || d.body).appendChild(s);
            })();
          </script>
          <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
        
        
      
    


    </div>
  </div>
  <div class="column one-fourth">
    
<h3>Search</h3>
<div id="site_search">
    <input type="text" id="search_box" placeholder="Search">
    <button class="btn btn-default" id="site_search_do"><span class="octicon octicon-search"></span></button>
</div>

<ul id="search_results"></ul>

<link rel="stylesheet" type="text/css" href="https://zmatsh.b0.upaiyun.com/assets/css/modules/sidebar-search.css">
<script src="https://zmatsh.b0.upaiyun.com/assets/js/lunr.min.js"></script>
<script src="https://zmatsh.b0.upaiyun.com/assets/js/search.js"></script>


    
<h3>Post Directory</h3>
<div id="post-directory-module" class="mobile-hidden">
  <section class="post-directory">
  <!-- Links that trigger the jumping -->
  <!-- Added by javascript below -->
  <dl></dl>
  </section>
</div>
<script src="https://zmatsh.b0.upaiyun.com/assets/js/jquery.toc.js"></script>

  </div>
</div>
</section>
<!-- /section.content -->

    <footer class="container">
        <div class="site-footer" role="contentinfo">
            <div class="copyright left mobile-block">
                    © 2015
                    <span title="breakeval13">breakeval13</span>
                    <a href="javascript:window.scrollTo(0,0)" class="right mobile-visible">TOP</a>
            </div>

            <ul class="site-footer-links right mobile-hidden">
                <li>
                    <a href="javascript:window.scrollTo(0,0)" >TOP</a>
                </li>
            </ul>
            <a href="http://github.com/breakEval13/breakEval13.github.io" target="_blank" aria-label="view source code">
                <span class="mega-octicon octicon-mark-github" title="GitHub"></span>
            </a>
            <ul class="site-footer-links mobile-hidden">
                
                <li>
                    <a href="/" title="Index" target="">Index</a>
                </li>
                
                <li>
                    <a href="/categories/" title="categories" target="">categories</a>
                </li>
                
                <li>
                    <a href="/open-source/" title="open-source" target="">open-source</a>
                </li>
                
                <li>
                    <a href="/wiki/" title="wiki" target="">wiki</a>
                </li>
                
                <li>
                    <a href="/links/" title="links" target="">links</a>
                </li>
                
                <li>
                    <a href="/about/" title="about" target="">about</a>
                </li>
                
                <li><a href="/feed.xml"><span class="octicon octicon-rss" style="color:orange;"></span></a></li>
            </ul>

        </div>
    </footer>
    <!-- / footer -->
    <script src="https://zmatsh.b0.upaiyun.com/assets/vendor/share.js/dist/js/share.min.js"></script>
    <script src="https://zmatsh.b0.upaiyun.com/assets/js/geopattern.js"></script>
    <script src="https://zmatsh.b0.upaiyun.com/assets/js/prism.js"></script>
    <link rel="stylesheet" href="https://zmatsh.b0.upaiyun.com/assets/css/globals/prism.css">
    <script>
      jQuery(document).ready(function($) {
        // geopattern
        $('.geopattern').each(function(){
          $(this).geopattern($(this).data('pattern-id'));
        });
       // hljs.initHighlightingOnLoad();
      });
    </script>
    
    <div style="display:none">
      <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-80669434-1', 'auto');
        ga('send', 'pageview');

      </script>
    </div>
    
</body>
    <script>
        (function(){
            var bp = document.createElement('script');
            var curProtocol = window.location.protocol.split(':')[0];
            if (curProtocol === 'https') {
                bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
            }
            else {
                bp.src = 'http://push.zhanzhang.baidu.com/push.js';
            }
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(bp, s);
        })();
    </script>
</html>
